{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "food_classification_EfficientNetB4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnE9oXRH+j2fRlNa8etF0r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imemmul/Food_classification_EfficientNetB4/blob/main/food_classification_EfficientNetB4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this colab aims to create a EfficientNetB4 model for 10 class food dataset and compare with B0"
      ],
      "metadata": {
        "id": "kRyRv9b4b-hV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data i get is Daniel Bourke's food data which is divided in to 3 datasets 1 percent, 10 percent and all."
      ],
      "metadata": {
        "id": "SdrsPajzcFY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKM8j3bndNfI",
        "outputId": "0eb3219e-e594-4b90-dcc1-a56a9dd955de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-31 10:56:34--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-31 10:56:34 (73.1 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dependencies\n",
        "import tensorflow as tf\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "n9znN8xzcX7V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Data ready"
      ],
      "metadata": {
        "id": "vQEPEu5mdzIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYYNWrMjd1tQ",
        "outputId": "29966dc1-f49d-4d2e-e7dc-e990630164ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-31 10:56:39--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 74.125.130.128, 74.125.68.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   275MB/s    in 0.6s    \n",
            "\n",
            "2022-08-31 10:56:40 (275 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "AAGeXWqpd6MY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"10_food_classes_10_percent/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0b9cLKzeAuT",
        "outputId": "6b99ca0f-4835-4164-8534-4b082e565f3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent/'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 75 images for training 250 images for testing\n",
        "\n",
        "train_dir_10 = \"10_food_classes_10_percent/train/\"\n",
        "test_dir_10 = \"10_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "yaSgTXTneEqe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "input_shape = (224, 224, 3)\n",
        "train_data_10 = tf.keras.utils.image_dataset_from_directory(train_dir_10,\n",
        "                                                            label_mode=\"categorical\",\n",
        "                                                            image_size=IMG_SIZE)\n",
        "\n",
        "test_data = tf. keras.utils.image_dataset_from_directory(test_dir_10,\n",
        "                                                         label_mode=\"categorical\",\n",
        "                                                         image_size=IMG_SIZE) # test_data will be always same so i am just attending it once "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTgdiNHVeSj7",
        "outputId": "92dc2c3c-1538-4c46-a908-2c5532b3d913"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_10.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StODZ1cMezeG",
        "outputId": "5594a296-00fb-48cb-e65b-c10816431f70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building model"
      ],
      "metadata": {
        "id": "vDyeMMuke1_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### We got data ready now its time to build model i am going to build 4 different models\n",
        "- model_1 is going to be our base model every tuning will be on this one.\n",
        "- model_2 is going to be only fitted by augmented data.\n",
        "- model_3 is going to be augmented data + tuning some layers on model_1 (which is not trainable on model_1)\n",
        "- model_4 is going to be using all data + model_3 tunings"
      ],
      "metadata": {
        "id": "q-zGd-r5fAJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.EfficientNetB4(include_top=False)\n",
        "model.trainable = False # freezing all the layers in model so that we can use them directly\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=input_shape) # this is our input layer\n",
        "x = model(inputs) # inputs passed to the model\n",
        "\n",
        "# its time pool before outputting\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x) # tf.reduce_mean(inputs, axis=[1, 2])\n",
        "\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x) # after pooled get outputs to dense layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVXW9RWnfd0w",
        "outputId": "c849f3d5-192d-4984-8380-4b8c8eb45fd6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
            "71688192/71686520 [==============================] - 2s 0us/step\n",
            "71696384/71686520 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "IY3QnmIPguY3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtyDlifxg63V",
        "outputId": "844a3265-8d78-4207-e93d-d4345e30fb24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb4 (Functional)  (None, None, None, 1792)  17673823 \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1792)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                17930     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,691,753\n",
            "Trainable params: 17,930\n",
            "Non-trainable params: 17,673,823\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before the fit i should create a checkpoint callback in order to call it while fitting"
      ],
      "metadata": {
        "id": "VOFd_Rz5he8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp_path = \"efficient_net_fit_weights/checkpoint\"\n",
        "cp_cb = tf.keras.callbacks.ModelCheckpoint(filepath=cp_path,\n",
        "                                           save_weights_only=True,\n",
        "                                           save_freq=\"epoch\",\n",
        "                                           verbose=0)"
      ],
      "metadata": {
        "id": "OTFO2oX9hkCv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(train_data_10,\n",
        "                        validation_data=test_data,\n",
        "                        steps_per_epoch=len(train_data_10),\n",
        "                        validation_steps=int(0.25*(len(test_data))),\n",
        "                        epochs=5) # just using 25% of test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIlv99BchSbJ",
        "outputId": "23426ddb-5e89-4eb9-dd5d-637355a27fbe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 34s 461ms/step - loss: 1.7847 - accuracy: 0.4933 - val_loss: 1.1426 - val_accuracy: 0.7418\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 8s 311ms/step - loss: 1.0182 - accuracy: 0.7480 - val_loss: 0.7952 - val_accuracy: 0.8076\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 8s 312ms/step - loss: 0.7618 - accuracy: 0.8187 - val_loss: 0.6736 - val_accuracy: 0.8240\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 8s 314ms/step - loss: 0.6300 - accuracy: 0.8413 - val_loss: 0.6242 - val_accuracy: 0.8322\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 8s 313ms/step - loss: 0.5529 - accuracy: 0.8587 - val_loss: 0.5838 - val_accuracy: 0.8339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though we used 10% of data + didn't make any differences tuning or etc. still we got 80 percent on test data."
      ],
      "metadata": {
        "id": "PjDyplB_ik6x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oliX5CpYjg7_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}